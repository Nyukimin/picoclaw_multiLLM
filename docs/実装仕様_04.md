以下、**workers/*.ts 側**でそのまま使える「雛形（入力 → LLM呼び出し → JSON抽出/パース → Ajvバリデーション → 標準出力）」のコピペ版。
依存は **ajv + ajv-formats** だけ。

---

## 0) 依存追加（一回だけ）

```bash
npm i ajv ajv-formats
```

---

## 1) `src/types/worker.ts`

```ts
// src/types/worker.ts
export type Route = "CHAT" | "PLAN" | "ANALYZE" | "OPS" | "RESEARCH" | "CODE";
export type Risk = "low" | "medium" | "high";
export type Channel = "slack" | "line";
export type TargetOS = "linux" | "windows" | "mac" | "unknown";

export interface WorkerInput {
  route: Route;
  session: {
    session_id: string;
    channel: Channel;
    target_os: TargetOS;
    timezone?: string;
    now_iso?: string;
    repo_hint?: { name?: string; path?: string; branch?: string };
  };
  user_text: string;
  context: {
    short_memory: string;
    recent_turns: Array<{ role: "user" | "assistant"; text: string }>;
  };
  flags: {
    local_only: boolean;
    prev_primary_route?: Route | null;
  };
  limits: {
    max_result_chars: number;
    max_questions?: number;
    max_next_actions?: number;
  };
  security?: {
    redact_patterns?: string[];
    cloud_allowed_routes?: string[];
  };
  tooling?: {
    web_search_available?: boolean;
    repo_read_available?: boolean;
  };
}

export interface WorkerOutput {
  result: any;
  needs_next_loop: boolean;
  why: string;
  next_actions: string[];
  questions_for_user: string[];
  confidence: number; // 0..1
  risk: Risk;
  fit: boolean;
  suggested_route: Route;
}
```

---

## 2) `src/llm/llmClient.ts`（インタフェースだけ）

```ts
// src/llm/llmClient.ts
export type ChatRole = "system" | "user";

export interface ChatMessage {
  role: ChatRole;
  content: string;
}

export interface LLMGenerateOptions {
  model: string;
  messages: ChatMessage[];
  timeoutMs: number;
  temperature?: number;
}

export interface LLMClient {
  generate(opts: LLMGenerateOptions): Promise<string>; // 生テキスト返し
}
```

---

## 3) `src/workers/workerOutputSchema.ts`（Ajv用スキーマ）

```ts
// src/workers/workerOutputSchema.ts
import type { JSONSchemaType } from "ajv";
import type { WorkerOutput } from "../types/worker";

export const workerOutputSchema: JSONSchemaType<WorkerOutput> = {
  type: "object",
  additionalProperties: true,
  required: [
    "result",
    "needs_next_loop",
    "why",
    "next_actions",
    "questions_for_user",
    "confidence",
    "risk",
    "fit",
    "suggested_route"
  ],
  properties: {
    result: {} as any,
    needs_next_loop: { type: "boolean" },
    why: { type: "string" },
    next_actions: { type: "array", items: { type: "string" } },
    questions_for_user: { type: "array", items: { type: "string" } },
    confidence: { type: "number", minimum: 0, maximum: 1 },
    risk: { type: "string", enum: ["low", "medium", "high"] },
    fit: { type: "boolean" },
    suggested_route: {
      type: "string",
      enum: ["CHAT", "PLAN", "ANALYZE", "OPS", "RESEARCH", "CODE"]
    }
  }
};
```

---

## 4) `src/workers/workerRunner.ts`（ここが本体）

````ts
// src/workers/workerRunner.ts
import Ajv from "ajv";
import addFormats from "ajv-formats";
import type { LLMClient } from "../llm/llmClient";
import type { Route, WorkerInput, WorkerOutput, Risk } from "../types/worker";
import { workerOutputSchema } from "./workerOutputSchema";

const ajv = new Ajv({ allErrors: true, strict: false });
addFormats(ajv);
const validateWorkerOutput = ajv.compile(workerOutputSchema);

export interface RunWorkerOptions {
  input: WorkerInput;
  client: LLMClient;
  model: string;
  timeoutMs: number;
  systemPrompt: string;
  userPrompt: string;
  // 失敗時の suggested_route（だいたい input.route でOK）
  fallbackSuggestedRoute?: Route;
}

function clamp01(n: number): number {
  if (Number.isNaN(n)) return 0;
  if (n < 0) return 0;
  if (n > 1) return 1;
  return n;
}

function safeArray(xs: any, max: number): string[] {
  if (!Array.isArray(xs)) return [];
  return xs
    .filter((v) => typeof v === "string" && v.trim().length > 0)
    .slice(0, max);
}

function limitString(s: string, maxChars: number): string {
  if (typeof s !== "string") return "";
  if (s.length <= maxChars) return s;
  return s.slice(0, maxChars);
}

/**
 * LLMがJSON以外を混ぜた時のための “最初のJSONオブジェクト/配列” 抜き出し
 * - 期待: workerはJSON objectだが、保険で array も拾う
 */
export function extractFirstJson(text: string): string | null {
  if (!text) return null;

  // 1) まず ```json ... ``` を優先
  const fenced = text.match(/```json\s*([\s\S]*?)\s*```/i);
  if (fenced?.[1]) return fenced[1].trim();

  // 2) 次に ``` ... ``` の中身（json指定なし）
  const fencedAny = text.match(/```\s*([\s\S]*?)\s*```/);
  if (fencedAny?.[1]) return fencedAny[1].trim();

  // 3) 最後に、生テキストから括弧対応で拾う（{...} or [...]
  const startIdx = (() => {
    const iObj = text.indexOf("{");
    const iArr = text.indexOf("[");
    if (iObj === -1) return iArr;
    if (iArr === -1) return iObj;
    return Math.min(iObj, iArr);
  })();
  if (startIdx === -1) return null;

  const open = text[startIdx];
  const close = open === "{" ? "}" : "]";
  let depth = 0;
  for (let i = startIdx; i < text.length; i++) {
    const ch = text[i];
    if (ch === open) depth++;
    if (ch === close) depth--;
    if (depth === 0) {
      return text.slice(startIdx, i + 1).trim();
    }
  }
  return null;
}

function buildFailureOutput(params: {
  route: Route;
  suggested_route: Route;
  risk?: Risk;
  why: string;
  errorHint?: string;
}): WorkerOutput {
  return {
    result: {
      error: params.errorHint ?? "worker_failed",
      route: params.route
    },
    needs_next_loop: false,
    why: params.why,
    next_actions: [],
    questions_for_user: [],
    confidence: 0,
    risk: params.risk ?? "medium",
    fit: false,
    suggested_route: params.suggested_route
  };
}

function postNormalize(output: WorkerOutput, input: WorkerInput): WorkerOutput {
  const maxQ = input.limits.max_questions ?? 3;
  const maxA = input.limits.max_next_actions ?? 3;

  output.confidence = clamp01(output.confidence);
  output.next_actions = safeArray(output.next_actions, maxA);
  output.questions_for_user = safeArray(output.questions_for_user, maxQ);

  // 文字列が長すぎると会話LLMの素材が溢れるので、resultが文字列なら制限
  if (typeof output.result === "string") {
    output.result = limitString(output.result, input.limits.max_result_chars);
  }
  // objectの場合も、雑に巨大化しがちならここで要約/カットする設計にできる（今回は最小限）

  // suggested_route が変でも守る
  const allowed: Route[] = ["CHAT", "PLAN", "ANALYZE", "OPS", "RESEARCH", "CODE"];
  if (!allowed.includes(output.suggested_route)) {
    output.suggested_route = input.route;
  }
  return output;
}

export async function runWorkerLLM(opts: RunWorkerOptions): Promise<WorkerOutput> {
  const { input, client, model, timeoutMs, systemPrompt, userPrompt } = opts;
  const suggested = opts.fallbackSuggestedRoute ?? input.route;

  let raw: string;
  try {
    raw = await client.generate({
      model,
      messages: [
        { role: "system", content: systemPrompt },
        { role: "user", content: userPrompt }
      ],
      timeoutMs,
      temperature: 0.1
    });
  } catch (e: any) {
    return buildFailureOutput({
      route: input.route,
      suggested_route: suggested,
      risk: "medium",
      why: "LLM呼び出しに失敗",
      errorHint: String(e?.message ?? e)
    });
  }

  const jsonText = extractFirstJson(raw);
  if (!jsonText) {
    return buildFailureOutput({
      route: input.route,
      suggested_route: suggested,
      risk: "medium",
      why: "JSON抽出に失敗",
      errorHint: "no_json_found"
    });
  }

  let parsed: any;
  try {
    parsed = JSON.parse(jsonText);
  } catch (e: any) {
    return buildFailureOutput({
      route: input.route,
      suggested_route: suggested,
      risk: "medium",
      why: "JSONパースに失敗",
      errorHint: "json_parse_error"
    });
  }

  const ok = validateWorkerOutput(parsed);
  if (!ok) {
    return buildFailureOutput({
      route: input.route,
      suggested_route: suggested,
      risk: "medium",
      why: "JSONバリデーションに失敗",
      errorHint: JSON.stringify(validateWorkerOutput.errors ?? [])
    });
  }

  return postNormalize(parsed as WorkerOutput, input);
}

/**
 * WorkerInput から userPrompt を組むための共通ヘルパ（必要なら各workerで自由に変えてOK）
 */
export function buildWorkerUserPrompt(input: WorkerInput): string {
  const payload = {
    route: input.route,
    session: input.session,
    user_text: input.user_text,
    context: input.context,
    flags: input.flags,
    limits: input.limits,
    tooling: input.tooling
  };
  return `WorkerInput(JSON):\n${JSON.stringify(payload, null, 2)}`;
}
````

---

## 5) `src/workers/planWorker.ts`（例：ローカル推論LLM）

```ts
// src/workers/planWorker.ts
import type { LLMClient } from "../llm/llmClient";
import type { WorkerInput, WorkerOutput } from "../types/worker";
import { runWorkerLLM, buildWorkerUserPrompt } from "./workerRunner";

const SYSTEM_PROMPT = `あなたは「planWorker」です。ユーザー入力を受け取り、段取り・仕様化・タスク分解の“素材”を作ります。
最終的なユーザー向け文章は作りません。出力は必ずJSONのみ。

# 禁止
- JSON以外を出力しない
- 断定しない（不明は不明）
- 秘密情報を推測して書かない

# result 形式（推奨）
result は object:
{
  "goal": "今回のゴール(1文)",
  "assumptions": ["前提/仮定(最大5)"],
  "decisions_needed": ["決める必要がある点(最大7)"],
  "plan": [{"step": 1, "title": "短い作業名", "details": ["要点(最大5)"], "check": ["完了条件(最大3)"]}],
  "risks": [{"item":"リスク", "mitigation":"回避策"}],
  "deliverables": ["成果物(最大5)"]
}

# 出力JSON（必須キー）
{
  "result": <上記>,
  "needs_next_loop": <true/false>,
  "why": "<理由>",
  "next_actions": ["最大3"],
  "questions_for_user": ["最大3、不要なら空配列"],
  "confidence": <0..1>,
  "risk": "low|medium|high",
  "fit": <true/false>,
  "suggested_route": "CHAT|PLAN|ANALYZE|OPS|RESEARCH|CODE"
}

JSON以外は絶対に出力しない。`;

export async function planWorker(params: {
  input: WorkerInput;
  client: LLMClient;     // 推論LLM（Ollama）
  model: string;
  timeoutMs: number;
}): Promise<WorkerOutput> {
  const userPrompt = buildWorkerUserPrompt(params.input);

  return runWorkerLLM({
    input: params.input,
    client: params.client,
    model: params.model,
    timeoutMs: params.timeoutMs,
    systemPrompt: SYSTEM_PROMPT,
    userPrompt
  });
}
```

---

## 6) `src/workers/codeWorker.ts`（例：クラウド、ただし /local は保険で拒否）

```ts
// src/workers/codeWorker.ts
import type { LLMClient } from "../llm/llmClient";
import type { WorkerInput, WorkerOutput } from "../types/worker";
import { runWorkerLLM, buildWorkerUserPrompt } from "./workerRunner";

const SYSTEM_PROMPT = `あなたは「codeWorker」です。差分（unified diff）またはファイル内容を生成します。
最終的なユーザー向け文章は作りません。出力は必ずJSONのみ。

# 禁止
- JSON以外を出力しない
- キー/トークン/パスワード等の秘密情報を埋め込まない
- 取得していない既存コードを捏造して断定しない

# result 形式（推奨）
result は object:
{
  "patch_unified": "unified diff（可能なら優先）",
  "files": [{"path":"relative/path","action":"create|modify|delete","content":"全文"}],
  "commands": [{"os":"linux|windows|mac","shell":"bash|powershell","cmd":"1行","why":"目的"}],
  "notes": ["注意点(最大5)"],
  "tests": ["最低限の確認(最大5)"]
}

# 出力JSON（必須キー）
{
  "result": <上記>,
  "needs_next_loop": <true/false>,
  "why": "<理由>",
  "next_actions": ["最大3"],
  "questions_for_user": ["最大3、不要なら空配列"],
  "confidence": <0..1>,
  "risk": "low|medium|high",
  "fit": <true/false>,
  "suggested_route": "CHAT|PLAN|ANALYZE|OPS|RESEARCH|CODE"
}

JSON以外は絶対に出力しない。`;

export async function codeWorker(params: {
  input: WorkerInput;
  client: LLMClient;     // クラウドコードLLM
  model: string;
  timeoutMs: number;
}): Promise<WorkerOutput> {
  // 本来はLoopControllerで弾くが、二重安全策
  if (params.input.flags.local_only) {
    return {
      result: { blocked: true, reason: "local_only=true" },
      needs_next_loop: false,
      why: "/local のためCODEは実行不可",
      next_actions: [],
      questions_for_user: [],
      confidence: 1,
      risk: "low",
      fit: false,
      suggested_route: "PLAN"
    };
  }

  const userPrompt = buildWorkerUserPrompt(params.input);

  return runWorkerLLM({
    input: params.input,
    client: params.client,
    model: params.model,
    timeoutMs: params.timeoutMs,
    systemPrompt: SYSTEM_PROMPT,
    userPrompt
  });
}
```

---

