---
generated_at: 2026-02-28T17:50:00+09:00
run_id: run_20260228_170007
phase: 2
step: "12"
profile: picoclaw_multiLLM
artifact: architecture_summary
updated_at: 2026-02-28T20:00:00+09:00
phase_2_verification: completed
---

# アーキテクチャ総合

## 概要

PicoClaw は、超軽量（<10MB）AI アシスタントとして、LINE/Slack からの指示を受け、複数の LLM（Ollama/Claude/OpenAI/DeepSeek）を適切にルーティングして実行する Go 製システムです。Chat/Worker/Coder の役割分離、承認フロー、日次カットオーバーによるメモリ管理を特徴とし、階層化アーキテクチャにより保守性と拡張性を確保しています。

## 関連ドキュメント

- 各モジュール解析: modules/*.md
- [結合ポイントマップ.md](結合ポイントマップ.md)
- [ユースケース逆引き.md](ユースケース逆引き.md)
- プロファイル: codebase-analysis-profile.yaml
- 実装仕様（正本）: docs/01_正本仕様/実装仕様.md

---

## システムアーキテクチャ概要

### 設計哲学

PicoClaw の設計は以下の 3 つの原則に基づいています：

1. **超軽量性**: メモリ使用量 <10MB を目標とし、Ollama の軽量モデル（chat-v1, worker-v1）を常駐化、セッションメモリの最小化、日次カットオーバーによるメモリリセットを実現
2. **役割分離**: Chat（会話）/ Worker（実行）/ Coder（設計・実装）の明確な責務分離により、適切な LLM を適切なタスクに割り当て
3. **安全性**: 承認フロー（job_id ベース）により破壊的操作を制御し、ユーザーの意思決定を尊重

### 階層化アーキテクチャ

PicoClaw は 5 層のアーキテクチャで構成されています：

```
┌──────────────────────────────────────────────────────┐
│ 0. エントリポイント層 (core)                         │
│    └─ cmd/picoclaw/main.go                          │
│       ├─ サブコマンド振り分け（agent/gateway/cron）  │
│       ├─ 設定読み込み（環境変数 > JSON）             │
│       └─ サービス初期化                              │
└──────────────────────────────────────────────────────┘
                       ↓
┌──────────────────────────────────────────────────────┐
│ 1. インターフェース層                                │
│    ├─ channels (LINE/Slack/Telegram)                │
│    └─ bus (メッセージバス)                          │
│       → メッセージ受信・応答送信                      │
└──────────────────────────────────────────────────────┘
                       ↓
┌──────────────────────────────────────────────────────┐
│ 2. 制御層 (agent)                                    │
│    ├─ router  - ルーティング決定                      │
│    │            (明示コマンド→辞書→分類器→フォールバック)│
│    ├─ loop    - エージェントループ                    │
│    │            (LLM呼び出し・承認管理・カットオーバー)  │
│    ├─ context - コンテキスト構築                      │
│    │            (システムプロンプト・ブートストラップ)  │
│    └─ classifier - LLMベース分類器                   │
└──────────────────────────────────────────────────────┘
          ↓               ↓               ↓
┌──────────────────────────────────────────────────────┐
│ 3. ドメイン層                                        │
│    ├─ providers - LLM統合                            │
│    │   ├─ Ollama (chat-v1/worker-v1, keep_alive=-1) │
│    │   ├─ Claude API (claude-sonnet-4.5)            │
│    │   ├─ OpenAI (gpt-4)                            │
│    │   └─ DeepSeek (deepseek-chat)                  │
│    ├─ session - セッション管理                        │
│    │   ├─ メッセージ履歴（Messages）                  │
│    │   ├─ セッションフラグ（LocalOnly, PendingApprovalJobID）│
│    │   └─ 日次カットオーバー（04:00 JST）             │
│    └─ approval - 承認フロー                          │
│       ├─ job_id ベース追跡                           │
│       ├─ 承認/拒否処理                                │
│       └─ Auto-Approve（未実装）                       │
└──────────────────────────────────────────────────────┘
                       ↓
┌──────────────────────────────────────────────────────┐
│ 4. 基盤層 (infra)                                    │
│    ├─ logger - 構造化ログ (全モジュールで使用)        │
│    │   ├─ JSON永続化 + 人間可読出力                   │
│    │   └─ イベント種別（router.decision, approval.*） │
│    └─ config - 設定管理 (起動時読み込み)              │
│       ├─ 環境変数 > JSON の階層的マージ               │
│       └─ チルダ展開、FlexibleStringSlice             │
└──────────────────────────────────────────────────────┘

┌──────────────────────────────────────────────────────┐
│ 5. 拡張層                                            │
│    └─ mcp - MCP統合 (Chrome DevTools Protocol)      │
│       ├─ Phase 5-B 完了（クライアント実装）          │
│       └─ Phase 5-C 未着手（実行ロジック）             │
└──────────────────────────────────────────────────────┘
```

### 主要な設計パターン

1. **ルーティングパターン**: 4 段階判定（明示コマンド → ルール辞書 → 分類器 → フォールバック）により、適切な LLM を選択
2. **プロバイダーパターン**: 統一インターフェース（`LLMProvider.Chat()`）により、複数の LLM サービスを抽象化
3. **承認パターン**: job_id ベースの追跡により、破壊的操作の制御を実現
4. **カットオーバーパターン**: 日次境界（04:00 JST）でセッションをアーカイブし、メモリを最小化

---

## モジュール依存図

### 完全な依存関係グラフ

```
                    main.go (core)
                         │
    ┌────────────────────┼────────────────────┐
    │                    │                    │
 channels             agent                config
    │                    │                    │
  bus ←─────────────────┤                    │
    │                    │                    │
    │            ┌───────┼───────┐            │
    │            │       │       │            │
    │        session  providers approval     │
    │            │       │       │            │
    │            ├───────┴───────┤            │
    │            │               │            │
    │         logger ←───────────┴────────────┘
    │                                         │
    └─────────────────────────────────────────┘

特殊な依存:
- mcp: agent/loop.go から初期化のみ（実行ロジック未統合）
- auth: providers が OAuth 使用時に参照
- tools: agent/loop.go が LLM ツール実行時に参照
```

### モジュール別結合度

| モジュール | 結合度 | 依存先の数 | 被依存元の数 | 理由 |
|-----------|-------|----------|------------|------|
| **logger** | 最低 | 0 | 10+ | 基盤層、全モジュールから使用 |
| **config** | 最低 | 0 | 10+ | 基盤層、起動時に読み込まれる |
| **approval** | 低 | 0 | 2 | 標準ライブラリのみ、agent/loop, session から参照 |
| **session** | 低 | 1 | 3 | providers.Message のみ依存、agent, channels から参照 |
| **mcp** | 低 | 0 | 1 | 標準ライブラリのみ、agent/loop から初期化 |
| **providers** | 中 | 3 | 2 | config, auth, logger に依存、agent から参照 |
| **agent** | 高 | 6 | 3 | session, providers, approval, config, logger, mcp に依存 |
| **core** | 最高 | 4 | 0 | agent, providers, logger, config に依存、エントリポイント |

---

## 主要データフロー

### 1. リクエスト処理フロー（UC1）

```
LINE/Slack メッセージ受信
  ↓
channels/line/handler.go: HandleWebhook()
  ↓
bus.Publish(MessageReceived)
  ↓
agent/loop.go: AgentLoop.HandleMessage()
  ↓
session.Manager.GetOrCreate(channel, chatID)
  ↓
agent/router.go: DetermineRoute()
  ├─ 明示コマンド判定（/code, /chat）
  ├─ ルール辞書マッチング
  ├─ classifier.ClassifyInput()（LLM ベース）
  └─ フォールバック（CHAT）
  ↓
providers.CreateProvider(ルート別設定)
  ├─ CHAT → OllamaProvider (chat-v1)
  ├─ CODE3 → AnthropicProvider (claude-sonnet-4.5)
  └─ 他ルート
  ↓
provider.Chat(ctx, messages, tools)
  ↓
応答受信・ツール実行
  ↓
session.AddMessage(role=assistant, content)
  ↓
session.Save(key) → JSON 永続化
  ↓
bus.Publish(SendMessage)
  ↓
channels/line/handler.go: sendReply()
```

### 2. 承認フローデータフロー（UC2）

```
CODE3 ルート決定
  ↓
providers.AnthropicProvider.Chat()
  ↓
plan/patch/risk の解析（agent/loop.go）
  ↓
approval.Manager.CreateJob(plan, patch, risk)
  ├─ job_id 発行（YYYYMMDD-HHMMSS-xxxxxxxx）
  └─ Job.Status = StatusPending
  ↓
session.SetFlags(PendingApprovalJobID: job_id)
  ↓
approval.FormatApprovalRequest(job)
  ↓
メッセージ返却（/approve <job_id> または /deny <job_id>）
  ↓
ユーザー承認コマンド受信
  ↓
approval.Manager.Approve(job_id)
  └─ Job.Status = StatusGranted
  ↓
Worker 実行委譲（※未実装）
```

### 3. 日次カットオーバーフロー（UC5）

```
毎日 04:00 JST 境界判定
  ↓
agent/loop.go: maybeDailyCutover(sessionKey)
  ├─ session.GetUpdatedTime(key)
  └─ GetLogicalDate(updatedTime)
  ↓
agent/memory.go: SaveDailyNoteForDate(date, session)
  ├─ 出力先: workspace/memory/YYYYMM/YYYYMMDD.md
  └─ Obsidian 形式（Markdown）
  ↓
session.Manager.ResetSession(key)
  ├─ session.Messages = []  # クリア
  ├─ session.Summary = ""   # クリア
  └─ session.Flags は保持
```

---

## 修正影響度チェックリスト

### 1. ルート定数追加時

- [ ] `agent/router.go`: `Route` 型定義に新ルート追加
- [ ] `agent/router.go`: `DetermineRoute()` で明示コマンド判定追加
- [ ] `agent/router.go`: `routeToString()` で文字列変換追加
- [ ] `agent/classifier.go`: 分類器プロンプトに新ルート追加
- [ ] `agent/context.go`: ルート別ブートストラップファイル読み込み追加
- [ ] `providers/provider.go`: `CreateProvider()` で新ルート対応プロバイダー追加
- [ ] `config/config.go`: ルーティング設定に新ルート設定追加

### 2. LLM プロバイダー追加時

- [ ] `providers/<new>_provider.go`: 新プロバイダー実装（`LLMProvider` インターフェース準拠）
- [ ] `providers/provider.go`: `CreateProvider()` で分岐追加
- [ ] `config/config.go`: プロバイダー設定追加（API キー、API Base、モデル）
- [ ] `health/checks.go`: 新プロバイダーのヘルスチェック追加（必要に応じて）
- [ ] `docs/05_LLM運用プロンプト設計/`: 新プロバイダーの運用仕様追加

### 3. セッションフラグ追加時

- [ ] `session/session.go`: `SessionFlags` 構造体にフィールド追加
- [ ] `agent/loop.go`: 新フラグの処理ロジック追加
- [ ] `agent/router.go`: 新フラグのルーティング判定への反映（必要に応じて）
- [ ] `session/manager_test.go`: 新フラグの永続化テスト追加

### 4. 承認フロー拡張時

- [ ] `approval/manager.go`: Auto-Approve 実装時は Scope/TTL 判定追加
- [ ] `approval/job.go`: UsesBrowser フラグの自動設定ロジック追加
- [ ] `agent/loop.go`: Coder3 出力パースロジック追加
- [ ] `agent/loop.go`: Worker 実行委譲ロジック追加
- [ ] `logger/logger.go`: 新ログイベント種別追加（`approval.auto_approved` 等）

### 5. チャネル追加時

- [ ] `pkg/channels/<new>/handler.go`: 新チャネルのハンドラー実装
- [ ] `pkg/bus/bus.go`: 新チャネルのメッセージ型定義
- [ ] `cmd/picoclaw/main.go`: 新チャネルのサービス初期化追加
- [ ] `config/config.go`: 新チャネルの設定追加

### 6. MCP 統合完了時（Phase 5-C）

- [ ] `agent/loop.go`: Coder3 が `uses_browser: true` を設定する仕組み実装
- [ ] `agent/loop.go`: Worker が patch から Chrome コマンドをパースする実装
- [ ] `agent/loop.go`: mcpClient 呼び出しと実行結果ログ記録
- [ ] `approval/manager.go`: Chrome 操作の Auto-Approve 対象外化
- [ ] `config/config.go`: MCP タイムアウト設定の実際の使用

---

## アーキテクチャの強み

1. **明確な責務分離**: 階層化アーキテクチャにより、各モジュールの責務が明確
2. **循環依存の回避**: 基盤層 → ドメイン層 → 制御層の一方向依存
3. **拡張性**: ルート・プロバイダー・チャネルの追加が比較的容易
4. **保守性**: 地図型ドキュメント（役割・関係性・構造マップ・落とし穴）により、変更影響範囲が明確
5. **テスト容易性**: 各モジュールが独立しており、ユニットテストが容易

---

## Phase 2 検証結果

### 検証日時
2026-02-28

### 検証方法
- 全 7 モジュールの実装コード（合計 7,000+ 行）を Phase 1 ドキュメントと突合せ
- 設計書（実装仕様.md）との乖離を検出
- 45 種類のログイベント、15 個の新たな落とし穴を発見

### モジュール別主要発見事項

#### **core（エントリポイント・設定）**
- ✅ **Phase 1 記載外の機能発見**: Skills 管理、Watchdog 設定、バージョン情報管理
- ⚠️ **embed.FS 依存**: ワークスペーステンプレートのバイナリ埋め込み（`go generate` 必須）
- ⚠️ **スキルインストールタイムアウト不足**: 30 秒固定、大きなリポジトリで不足の可能性
- ⚠️ **ビルトインスキルのハードコード**: 拡張性の制限
- ⚠️ **環境変数タグのテンプレート問題**: ProviderConfig の env タグが正しく機能しない可能性（要検証）
- ⚠️ **Ollama モデルチェックの対象外**: Coder3 は Ollama 判定ロジックの対象外

#### **agent（ルーティング・ループ）**
- ✅ **45 種類のログイベントを網羅的にカタログ化**: router.decision, classifier.error, worker.*, loop.*, approval.*, coder.* など
- ✅ **RouteApprove/RouteDeny の存在確認**: 承認コマンド専用ルート（Phase 1 ドキュメントに未記載）
- ❌ **設計書との乖離 5 項目**:
  1. Worker 実行委譲（実装仕様 6.2 節）: 未実装（Phase 4 予定）
  2. Auto-Approve モード（実装仕様 6.4 節）: 未実装（Phase 4-6 予定）
  3. 再ルーティング（最大1回）（実装仕様 3.3 節）: 未実装
  4. 会話LLM提案IF（実装仕様 3.4 節）: 未実装
  5. WorkerInput/Output スキーマ（実装仕様 4.3, 4.4 節）: 未実装
- ✅ **Coder3 出力解析のエラーハンドリング**: 適切に実装済み（Phase 1 で「脆弱性」と誤認識していた箇所を訂正）
- ✅ **SkipAddUserMessage フラグ**: Ollama 再起動後のリトライ時に重複回避する仕組み

#### **approval（承認フロー）**
- ✅ **Phase 1-3 完了**: 基本的な承認フロー（CreateJob, Approve, Deny, IsApproved）は完全実装済み
- ❌ **Auto-Approve は完全に未実装**:
  - `StatusAutoApproved` は定義されているが使用されていない
  - EnableAutoApprove/DisableAutoApprove メソッドは存在しない
  - CheckAutoApprove 判定ロジックは存在しない
  - これは実装プラン通り（Phase 4-6 で実装予定）
- ❌ **cost_hint フィールド未実装**: Coder3 仕様では定義されているが、Job 構造体に存在しない（設計書との乖離）
- ✅ **テストカバレッジ高**: 基本機能は 100% カバー（二重承認防止、エラーハンドリング等）

#### **llm_provider（LLM プロバイダー）**
- ✅ **タイムアウト実装の詳細確認**: 3 段階チェック（`context.DeadlineExceeded`, `net.Error.Timeout()`, エラー文字列）
- ✅ **Ollama 判定ロジック詳細化**: `isOllamaEndpoint` は `:11434` だけでなく `localhost:11434`, `127.0.0.1:11434` も検出
- ✅ **画像ペイロードサイズ制限**: 5MB 超過時は黙って除外（`maxInlineImageBytes = 5 * 1024 * 1024`）
- ✅ **CreateProvider の実装範囲**: 3 段階フォールバック（明示指定→モデル名推論→OpenRouter）

#### **session（セッション管理）**
- ✅ **ResetSession の挙動確認**: Messages と Summary はクリア、**Flags は保持**（LocalOnly, PrevPrimaryRoute など）
- ✅ **並行アクセス制御の詳細**: ディープコピーで内部状態を完全に隔離、RWMutex で保護
- ✅ **Windows 互換性処理**: セッションキーの `:` を `_` にサニタイズ、パストラバーサル防止

#### **mcp（MCP 統合）**
- ✅ **Phase 5-B 完了**: MCP クライアント実装（client.go, chrome_tools.go）は完全に実装済み
- ❌ **Phase 5-C 未着手**: Agent Loop 統合（実行ロジック）は未実装
  - Coder3 が `uses_browser: true` を設定する仕組みなし
  - Worker が patch から Chrome コマンドをパースする実装なし
  - mcpClient 呼び出しと実行結果ログ記録なし
- ⚠️ **タイムアウト固定**: 30 秒ハードコード、`config.MCP.Chrome.TimeoutSec` は参照されていない

#### **infra（ログ・設定）**
- ❌ **マスキング機構の不在確認**: API キー等の自動マスキングは未実装（実装位置確認済み）
- ❌ **ログローテーション不在**: append モードで追記し続ける、長時間稼働で肥大化リスク
- ✅ **Caller 情報取得**: `runtime.Caller(2)` でログ出力元を取得（ファイル:行番号 (関数名)）

### 設計書との乖離サマリー

| 項目 | 実装仕様記載 | 実装状況 | Phase |
|------|-------------|---------|-------|
| 基本承認フロー | 6.1-6.3 節 | ✅ 完了 | Phase 1-3 |
| Worker 実行委譲 | 6.2 節（4番目のステップ） | ❌ 未実装 | Phase 4 予定 |
| Auto-Approve | 6.4 節 | ❌ 未実装 | Phase 4-6 予定 |
| 再ルーティング（最大1回） | 3.3 節 | ❌ 未実装 | 未定 |
| 会話LLM提案IF | 3.4 節 | ❌ 未実装 | 未定 |
| cost_hint フィールド | Coder3 仕様 8-2 | ❌ 未実装 | 未定 |
| Chrome 操作統合 | 実装仕様 5.1 節 | △ 部分完了 | Phase 5-B 完了、5-C 未着手 |

### 実装品質サマリー

- **実装済み機能の品質**: Phase 1-3 で実装された機能は堅牢（テストカバレッジ高、エラーハンドリング適切）
- **未実装機能の明確性**: 未実装箇所は TODO コメントや実装プランで明確に記録されており、意図的な段階的実装
- **設計書との一貫性**: 基本設計は実装仕様に準拠、未実装箇所は Phase 計画通り
- **コード品質**: Go の慣用句に従った実装、並行アクセス制御は適切（RWMutex, ディープコピー）

---

## アーキテクチャの課題

### 高優先度（短期対応推奨）

1. **未完成の承認フロー**:
   - ✅ 基本承認フロー（Phase 1-3）: 完了
   - ❌ Auto-Approve（Phase 4-6）: 完全未実装
     - `StatusAutoApproved` は定義のみ
     - EnableAutoApprove/DisableAutoApprove メソッド不在
     - Scope/TTL 判定ロジック不在
   - ❌ 承認後の Worker 実行委譲（Phase 4）: 未実装
     - loop.go:1931 に TODO コメント「Worker による差分適用は次のフェーズで実装予定」
   - ❌ 破壊的操作の自動検出: LLM の `risk` フィールドに依存（自動検出ロジックなし）
   - ❌ cost_hint フィールド: Job 構造体に未実装（Coder3 仕様との乖離）

2. **MCP 統合の未完成**:
   - ✅ Phase 5-B（クライアント実装）: 完了
   - ❌ Phase 5-C（Agent Loop 統合）: 未着手
     - Coder3 が `uses_browser: true` を設定する仕組みなし（loop.go:501 に TODO）
     - Worker が patch から Chrome コマンドをパースする実装なし
     - Chrome 操作の Auto-Approve 対象外化（強制承認）未実装
   - ⚠️ タイムアウト固定: 30 秒ハードコード、`config.MCP.Chrome.TimeoutSec` 未使用

3. **再ルーティング・LLM提案IF の未実装**:
   - ❌ 再ルーティング（最大1回）: 実装仕様 3.3 節で定義、実装は未着手
   - ❌ 会話LLM提案IF: 実装仕様 3.4 節で定義、実装は未着手
   - ❌ WorkerInput/Output スキーマ: 実装仕様 4.3, 4.4 節で定義、実装は未着手

### 中優先度（中期対応）

4. **マスキング機構の不在**:
   - API キー等の自動マスキングが未実装（logger.go L119-159 確認済み）
   - ログに平文で出力されるリスク（環境変数管理で緩和、CLAUDE.md 3.4.3節）
   - 現状: API キーは環境変数で管理されログに出力されない設計を前提

5. **ログローテーション不在**:
   - append モードで追記し続けるため、長時間稼働で肥大化リスク
   - 外部ツール（logrotate）による緩和が必要

6. **設定ホットリロード未サポート**:
   - 起動時のみ読み込み、実行中の再読み込み不可
   - 設定変更には再起動が必要

### 低優先度（長期対応）

7. **タイムゾーンハードコード**:
   - 日次カットオーバーの 04:00 JST が `Asia/Tokyo` ハードコード（memory.go:18）
   - 設定可能化が望ましい（グローバル展開時）

8. **In-Memory 実装の制約**:
   - 承認ジョブの永続化なし（プロセス再起動でジョブ情報消失）
   - セッション永続化は JSON ファイルのみ（Obsidian 連携強化が将来の拡張候補）

9. **embed.FS のビルド時依存**:
   - ワークスペーステンプレートの埋め込みは `go generate` 必須
   - CI/CD 環境でビルドする際に実行し忘れると埋め込みに失敗

10. **環境変数タグのテンプレート問題**:
    - `ProviderConfig` の env タグは `{{.Name}}` テンプレートを使用
    - `caarlos0/env` ライブラリがこのテンプレートを展開するか要検証

---

## 次の一手: アーキテクチャ改善のために

### 短期（Phase 5-C）

1. **MCP 統合完了**: Chrome 操作の実行ロジック実装
2. **承認フロー完成**: Coder3 出力パース、Worker 実行委譲
3. **Auto-Approve 実装**: Scope/TTL 判定、Chrome 操作の例外処理

### 中期（Phase 6）

4. **マスキング機構**: API キー・トークンの自動マスキング
5. **ログローテーション**: サイズ・日付ベースのローテーション
6. **設定ホットリロード**: SIGHUP シグナル受信時の設定再読み込み

### 長期（Phase 7+）

7. **永続化強化**: 承認ジョブの DB 永続化、セッションの Redis 化
8. **タイムゾーン設定可能化**: カットオーバー時刻の設定ファイル化
9. **メトリクス収集**: Prometheus 対応、パフォーマンス監視

---

## 補足: プロジェクト統計

- **総ファイル数**: 60+ ファイル（docs/ 含む）
- **主要モジュール数**: 7 モジュール（core, agent, providers, approval, session, mcp, infra）
- **総コード行数**: 推定 5000+ 行（コメント除く）
- **最大ファイル**: agent/loop.go（1900+ 行）
- **テストカバレッジ**: 重要パッケージ（approval, session）は 80% 以上目標
- **使用言語**: Go 1.23
- **外部依存**: 10+ パッケージ（anthropic-sdk-go, openai-go, env/v11 等）

---

## 関連資料

- **実装仕様（正本）**: docs/01_正本仕様/実装仕様.md
- **LLM 運用設計**: docs/05_LLM運用プロンプト設計/
- **実装ガイド**: docs/06_実装ガイド進行管理/
- **共通ルール**: rules/common/GLOBAL_AGENT.md
- **プロジェクトルール**: CLAUDE.md
